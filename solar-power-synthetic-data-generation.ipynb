{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generate Synthetic Data and Trigger Model Performance Workflow\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Kernel `Python 3 (ipykernal)` works well with this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "This tutorial shows you how to generate 2 synthetic dataset:\n",
    "1. Synthetic Autopilot generated result: use in model performance evaluation\n",
    "2. Synthetic historical solar power data: include daily ground truth and use in model evaluation and Autopilot training\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "1. [Setup](#Setup)\n",
    "2. [Create sample dataset](#sample_data)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Setup <a class=\"anchor\" id=\"Setup\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install --upgrade boto3 --quiet\n",
    "!pip install --upgrade sagemaker --quiet\n",
    "!pip install --upgrade pandas --quiet\n",
    "!pip install --upgrade numpy --quiet\n",
    "!pip install --upgrade matplotlib --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, let's obtain S3 bucket name used to store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Retrieve the account ID and Region\n",
    "region = boto3.Session().region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "#Obtain bucket name\n",
    "bucket_name = \"solar-power-forecast-{}-{}\".format(account_id, region)\n",
    "print(\"Bucket name is: {}.\".format(bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create sample dataset <a class=\"anchor\" id=\"sample_data\"></a>\n",
    "\n",
    "This part shows you how to generate 2 synthetic dataset: \n",
    "1. Synthetic Autopilot generated result\n",
    "2. Synthetic historical solar power data\n",
    "\n",
    "In reality, the dataset can be huge, and you may need to leverage tools like Amazon Athena or Amazon SageMaker Processor Job to process the data.\n",
    "\n",
    "For the purposes of this example, we simplified the process: synthesize the data in this notebook, write it locally, then upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of solar panels and maximum capacity\n",
    "num_panels = 1\n",
    "max_capacity = 350  # in watts\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Define the start and end dates for the 3-month period\n",
    "n_day = 15\n",
    "now = datetime.now()\n",
    "today = datetime(now.year, now.month, now.day)\n",
    "start_date = today - timedelta(days=n_day)\n",
    "predict_start_time = today - timedelta(days=1)\n",
    "\n",
    "# Convert the string to a datetime object\n",
    "formatted_time = datetime.strptime(str(predict_start_time), '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solar_power_data(start_date, end_date, num_panels, max_capacity):\n",
    "    \"\"\"\n",
    "    Generate power generation data for each solar panel and every 15-minute interval.\n",
    "\n",
    "    :param start_date: The starting datetime for data generation.\n",
    "    :param end_date: The ending datetime for data generation.\n",
    "    :param num_panels: Number of solar panels.\n",
    "    :param max_capacity: Maximum power capacity of solar panel.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for panel_id in range(1, num_panels + 1):\n",
    "        current_date = start_date\n",
    "        while current_date < end_date:\n",
    "            for minute in range(0, 60 * 24, 15):\n",
    "                timestamp = current_date + timedelta(minutes=minute)\n",
    "                hour = timestamp.hour\n",
    "\n",
    "                # Simulate the sun level based on the time of day\n",
    "                if 6 <= hour < 18:  # Daytime hours (6 AM to 6 PM)\n",
    "                    sun_level = np.sin((hour - 6) * np.pi / 12) * ((100 + random.randint(-10, 10)) / 100)\n",
    "                else:\n",
    "                    sun_level = 0.0  # No sun during nighttime\n",
    "\n",
    "                # Introduce noise to the max_capacity for each data point\n",
    "                noisy_max_capacity = max_capacity * np.random.normal(loc=1.0, scale=0.10)  # 10% standard deviation\n",
    "\n",
    "                # Calculate the actual power generation based on sun level and noisy maximum capacity\n",
    "                power = sun_level * noisy_max_capacity\n",
    "\n",
    "                # Add the data to the list\n",
    "                data.append([panel_id, timestamp, power])\n",
    "\n",
    "            current_date += timedelta(days=1)  # Move to the next day\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize Autopilot generated result\n",
    "\n",
    "The structure of the data generated is as follows:\n",
    "* __id__: (required: ItemIdentifierAttributeName)\n",
    "* __timestamp__: (required: TimestampAttributeName)\n",
    "* __p50__: Predicted result. The true value is expected to be lower than the predicted value 50% of the time. This is also known as the median forecast. [Read more here](https://docs.aws.amazon.com/forecast/latest/dg/metrics.html#metrics-wQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate historical power data for the last 2 weeks\n",
    "# Lower the max_capacity to create high drifting of synthetic model prediction result to trigger retraining\n",
    "data = generate_solar_power_data(predict_start_time, today, num_panels, max_capacity-200) \n",
    "\n",
    "# Define column names\n",
    "column_names = ['id', 'timestamp', 'p50']\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df_result = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the first 10 row\n",
    "df_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Plot the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(df_result['timestamp'], df_result['p50'])\n",
    "plt.title('Autopilot Predicted Power')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'solar_power_data.csv'\n",
    "local_file_path = 'pred_solar_power_data.csv'\n",
    "s3_file_path = 'data/pred/{}/{}'.format(formatted_time, file_name)\n",
    "\n",
    "try:\n",
    "    # Save data to CSV\n",
    "    df_result.to_csv(local_file_path, index=False)\n",
    "\n",
    "    # Upload the file\n",
    "    s3.upload_file(local_file_path, bucket_name, s3_file_path)\n",
    "    print(f\"File successfully uploaded to {bucket_name}/{s3_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize historical power data\n",
    "\n",
    "The structure of the data generated is as follows:\n",
    "* __id__: (required: ItemIdentifierAttributeName)\n",
    "* __timestamp__: (required: TimestampAttributeName)\n",
    "* __actual_power__: (required: TargetAttributeName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate historical power data for the last 2 weeks\n",
    "data = generate_solar_power_data(start_date, today, num_panels, max_capacity)\n",
    "\n",
    "# Define column names\n",
    "column_names = ['id', 'timestamp', 'actual_power']\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df_hist = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the first 10 row\n",
    "df_hist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Plot the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(df_hist['timestamp'], df_hist['actual_power'])\n",
    "plt.title('Historical Power')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is uploaded to `s3://\\<your-bucket>/data/hist/...` path, the `object_create` event will trigger the AWS Step Function to start the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'solar_power_data.csv'\n",
    "local_file_path = 'hist_solar_power_data.csv'\n",
    "s3_file_path = 'data/hist/{}/{}'.format(formatted_time, file_name)\n",
    "\n",
    "try:\n",
    "    # Save data to CSV\n",
    "    df_hist.to_csv(local_file_path, index=False)\n",
    "\n",
    "    # Upload the file\n",
    "    s3.upload_file(local_file_path, bucket_name, s3_file_path)\n",
    "    print(f\"File successfully uploaded to {bucket_name}/{s3_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
